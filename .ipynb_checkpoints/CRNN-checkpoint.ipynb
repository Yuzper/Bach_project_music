{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1795e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (1.21.5)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.3-cp39-cp39-win_amd64.whl (176 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (4.1.1)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.7.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from librosa) (1.7.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (61.2.0)\n",
      "Collecting platformdirs>=2.5.0\n",
      "  Downloading platformdirs-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jespe\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Building wheels for collected packages: audioread\n",
      "  Building wheel for audioread (setup.py): started\n",
      "  Building wheel for audioread (setup.py): finished with status 'done'\n",
      "  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23706 sha256=0dae30c6d2e771189feb53f331884d4d61eb08f5c1a6b136e0cad03936d0ee37\n",
      "  Stored in directory: c:\\users\\jespe\\appdata\\local\\pip\\cache\\wheels\\e4\\76\\a4\\cfb55573167a1f5bde7d7a348e95e509c64b2c3e8f921932c3\n",
      "Successfully built audioread\n",
      "Installing collected packages: platformdirs, soxr, soundfile, pooch, lazy-loader, audioread, librosa\n",
      "Successfully installed audioread-3.0.0 lazy-loader-0.1 librosa-0.10.0 platformdirs-3.0.0 pooch-1.7.0 soundfile-0.12.1 soxr-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "import librosa\n",
    "import numpy as np\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b6b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the melgram from the raw music file.\n",
    "def compute_melgram(audio_path):\n",
    "    ''' Compute a mel-spectrogram and returns it in a shape of (1,1,96,1366), where\n",
    "    96 == #mel-bins and 1366 == #time frame parameters\n",
    "    ----------\n",
    "    audio_path: path for the audio file. Any format supported by audioread will work.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # mel-spectrogram parameters\n",
    "    SR = 12000\n",
    "    N_FFT = 512\n",
    "    N_MELS = 96\n",
    "    HOP_LEN = 256\n",
    "    DURA = 29.12  # to make it 1366 frame..\n",
    "\n",
    "    src, sr = librosa.load(audio_path, sr=SR)  # whole signal\n",
    "    n_sample = src.shape[0]\n",
    "    n_sample_fit = int(DURA*SR)\n",
    "\n",
    "    if n_sample < n_sample_fit:  # if too short\n",
    "        src = np.hstack((src, np.zeros((int(DURA*SR) - n_sample,))))\n",
    "    elif n_sample > n_sample_fit:  # if too long\n",
    "        src = src[(n_sample-n_sample_fit)/2:(n_sample+n_sample_fit)/2]\n",
    "    logam = librosa.logamplitude\n",
    "    melgram = librosa.feature.melspectrogram\n",
    "    ret = logam(melgram(y=src, sr=SR, hop_length=HOP_LEN,\n",
    "                        n_fft=N_FFT, n_mels=N_MELS)**2,\n",
    "                ref_power=1.0)\n",
    "    ret = ret[np.newaxis, np.newaxis, :]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa778d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df35ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MusicTaggerCRNN(weights='msd', input_tensor=None):\n",
    "    '''Instantiate the MusicTaggerCRNN architecture, optionally loading weights pre-trained\n",
    "    on Million Song Dataset. Note that when using TensorFlow, for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one specified in your Keras config file.\n",
    "    For preparing mel-spectrogram input, see\n",
    "    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
    "    You will need to install [Librosa](http://librosa.github.io/librosa/) to use it.\n",
    "    # Arguments\n",
    "        weights: one of `None` (random initialization) or \"msd\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`) to use as image input for the model.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "\n",
    "    if weights not in {'msd', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `msd` '\n",
    "                         '(pre-training on Million Song Dataset).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape = (1, 96, 1366)\n",
    "    else:\n",
    "        input_shape = (96, 1366, 1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        melgram_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        melgram_input = Input(shape=input_tensor)\n",
    "\n",
    "    # Determine input axis\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "        freq_axis = 2\n",
    "        time_axis = 3\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "        freq_axis = 1\n",
    "        time_axis = 2\n",
    "\n",
    "    # Input block\n",
    "    x = ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
    "    x = BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n",
    "\n",
    "    # Conv block 1\n",
    "    x = Convolution2D(64, 3, 3, border_mode='same', name='conv1', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn1', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout1', trainable=False)(x)\n",
    "\n",
    "    # Conv block 2\n",
    "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv2', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn2', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout2', trainable=False)(x)\n",
    "\n",
    "    # Conv block 3\n",
    "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv3', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout3', trainable=False)(x)\n",
    "\n",
    "    # Conv block 4\n",
    "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv4', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn4', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout4', trainable=False)(x)\n",
    "\n",
    "    # reshaping\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = Permute((3, 1, 2))(x)\n",
    "    x = Reshape((15, 128))(x)\n",
    "\n",
    "    # GRU block 1, 2, output\n",
    "    x = GRU(32, return_sequences=True, name='gru1')(x)\n",
    "    x = GRU(32, return_sequences=False, name='gru2')(x)\n",
    "    x = Dropout(0.3, name='final_drop')(x)\n",
    "\n",
    "    if weights is None:\n",
    "        # Create model\n",
    "        x = Dense(10, activation='sigmoid',name='output')(x)\n",
    "        model = Model(melgram_input, x)\n",
    "        return model\n",
    "    else:\n",
    "        # Load input\n",
    "        x = Dense(50, activation='sigmoid', name='output')(x)\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
    "                               \"You can set it at ~/.keras/keras.json\")\n",
    "        # Create model\n",
    "        initial_model = Model(melgram_input, x)\n",
    "        initial_model.load_weights('weights/music_tagger_crnn_weights_%s.h5' % K._BACKEND,\n",
    "                           by_name=True)\n",
    "\n",
    "        # Eliminate last layer\n",
    "        pop_layer(initial_model)\n",
    "\n",
    "        # Add new Dense layer\n",
    "        last = initial_model.get_layer('final_drop')\n",
    "        preds = (Dense(10, activation='sigmoid', name='preds'))(last.output)\n",
    "        model = Model(initial_model.input, preds)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3641ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e163d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
