{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9098ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa\n",
    "import librosa\n",
    "import numpy as np\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155c201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the melgram from the raw music file.\n",
    "def compute_melgram(audio_path):\n",
    "    ''' Compute a mel-spectrogram and returns it in a shape of (1,1,96,1366), where\n",
    "    96 == #mel-bins and 1366 == #time frame parameters\n",
    "    ----------\n",
    "    audio_path: path for the audio file. Any format supported by audioread will work.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # mel-spectrogram parameters\n",
    "    SR = 12000\n",
    "    N_FFT = 512\n",
    "    N_MELS = 96\n",
    "    HOP_LEN = 256\n",
    "    DURA = 29.12  # to make it 1366 frame..\n",
    "\n",
    "    src, sr = librosa.load(audio_path, sr=SR)  # whole signal\n",
    "    n_sample = src.shape[0]\n",
    "    n_sample_fit = int(DURA*SR)\n",
    "\n",
    "    if n_sample < n_sample_fit:  # if too short\n",
    "        src = np.hstack((src, np.zeros((int(DURA*SR) - n_sample,))))\n",
    "    elif n_sample > n_sample_fit:  # if too long\n",
    "        src = src[(n_sample-n_sample_fit)/2:(n_sample+n_sample_fit)/2]\n",
    "    logam = librosa.logamplitude\n",
    "    melgram = librosa.feature.melspectrogram\n",
    "    ret = logam(melgram(y=src, sr=SR, hop_length=HOP_LEN,\n",
    "                        n_fft=N_FFT, n_mels=N_MELS)**2,\n",
    "                ref_power=1.0)\n",
    "    ret = ret[np.newaxis, np.newaxis, :]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53acf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb55248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MusicTaggerCRNN(weights='msd', input_tensor=None):\n",
    "    '''Instantiate the MusicTaggerCRNN architecture, optionally loading weights pre-trained\n",
    "    on Million Song Dataset. Note that when using TensorFlow, for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one specified in your Keras config file.\n",
    "    For preparing mel-spectrogram input, see\n",
    "    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
    "    You will need to install [Librosa](http://librosa.github.io/librosa/) to use it.\n",
    "    # Arguments\n",
    "        weights: one of `None` (random initialization) or \"msd\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`) to use as image input for the model.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "\n",
    "    if weights not in {'msd', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `msd` '\n",
    "                         '(pre-training on Million Song Dataset).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape = (1, 96, 1366)\n",
    "    else:\n",
    "        input_shape = (96, 1366, 1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        melgram_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        melgram_input = Input(shape=input_tensor)\n",
    "\n",
    "    # Determine input axis\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "        freq_axis = 2\n",
    "        time_axis = 3\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "        freq_axis = 1\n",
    "        time_axis = 2\n",
    "\n",
    "    # Input block\n",
    "    x = ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
    "    x = BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n",
    "\n",
    "    # Conv block 1\n",
    "    x = Convolution2D(64, 3, 3, border_mode='same', name='conv1', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn1', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout1', trainable=False)(x)\n",
    "\n",
    "    # Conv block 2\n",
    "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv2', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn2', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout2', trainable=False)(x)\n",
    "\n",
    "    # Conv block 3\n",
    "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv3', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn3', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout3', trainable=False)(x)\n",
    "\n",
    "    # Conv block 4\n",
    "    x = Convolution2D(128, 3, 3, border_mode='same', name='conv4', trainable=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn4', trainable=False)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4', trainable=False)(x)\n",
    "    x = Dropout(0.1, name='dropout4', trainable=False)(x)\n",
    "\n",
    "    # reshaping\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = Permute((3, 1, 2))(x)\n",
    "    x = Reshape((15, 128))(x)\n",
    "\n",
    "    # GRU block 1, 2, output\n",
    "    x = GRU(32, return_sequences=True, name='gru1')(x)\n",
    "    x = GRU(32, return_sequences=False, name='gru2')(x)\n",
    "    x = Dropout(0.3, name='final_drop')(x)\n",
    "\n",
    "    if weights is None:\n",
    "        # Create model\n",
    "        x = Dense(10, activation='sigmoid',name='output')(x)\n",
    "        model = Model(melgram_input, x)\n",
    "        return model\n",
    "    else:\n",
    "        # Load input\n",
    "        x = Dense(50, activation='sigmoid', name='output')(x)\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n",
    "                               \"You can set it at ~/.keras/keras.json\")\n",
    "        # Create model\n",
    "        initial_model = Model(melgram_input, x)\n",
    "        initial_model.load_weights('weights/music_tagger_crnn_weights_%s.h5' % K._BACKEND,\n",
    "                           by_name=True)\n",
    "\n",
    "        # Eliminate last layer\n",
    "        pop_layer(initial_model)\n",
    "\n",
    "        # Add new Dense layer\n",
    "        last = initial_model.get_layer('final_drop')\n",
    "        preds = (Dense(10, activation='sigmoid', name='preds'))(last.output)\n",
    "        model = Model(initial_model.input, preds)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26335279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448b3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
